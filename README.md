# ğŸ“Š Analisador de Sentimentos com spaCy (via Regras)

Este projeto utiliza a biblioteca [spaCy](https://spacy.io/) para **detectar o sentimento de frases** com base em **regras simples de palavras-chave**, usando os componentes `Matcher` e `PhraseMatcher`.

## ğŸš€ Objetivo

Classificar frases como **POSITIVO**, **NEGATIVO** ou **NEUTRO** com base em palavras e expressÃµes detectadas no texto. Isso Ã© feito **sem treinamento de modelo**, apenas por meio de padrÃµes linguÃ­sticos definidos manualmente.

---

## ğŸ§  Como funciona

O sistema segue os seguintes passos:

1. **Cria uma pipeline vazia do spaCy para portuguÃªs**.
2. **Define listas de palavras e expressÃµes positivas e negativas**.
3. **Cria dois tipos de matchers:**
   - `Matcher`: para palavras individuais.
   - `PhraseMatcher`: para detectar expressÃµes compostas.
4. **Cria uma extensÃ£o personalizada no objeto `Doc` do spaCy**, que calcula o sentimento com base nas correspondÃªncias.
5. **Analisa uma lista de frases e imprime o sentimento de cada uma**.

---

## ğŸ“¦ DependÃªncias

- Python 3.7+
- spaCy (v3+)

InstalaÃ§Ã£o:
```bash
pip install spacy
python -m spacy download pt_core_news_sm  # Caso queira usar um modelo treinado futuramente
```

---

## ğŸ§¾ CÃ³digo completo comentado

```python
import spacy
from spacy.matcher import Matcher, PhraseMatcher
from spacy.tokens import Doc

# 1. Criar pipeline spaCy em branco para portuguÃªs
nlp = spacy.blank("pt")

# 2. Listas de palavras e expressÃµes
palavras_positivas = ["incrÃ­vel", "amei", "divertido", "adorei", "maravilhosa", "obra-prima", "bom", "superou", "gostei", "linda", "recomendo"]
palavras_negativas = ["pÃ©ssimo", "cansativo", "sem graÃ§a", "ruim", "chato", "decepcionante", "horrÃ­vel", "sono", "mal feito", "sem sentido"]

# 3. Criar os matchers
matcher = Matcher(nlp.vocab)  # Para palavras simples
phrase_matcher = PhraseMatcher(nlp.vocab)  # Para expressÃµes compostas

# Adicionar padrÃµes de palavras (MATCHER)
for palavra in palavras_positivas:
    matcher.add("POSITIVO", [[{"LOWER": palavra}]])
for palavra in palavras_negativas:
    matcher.add("NEGATIVO", [[{"LOWER": palavra}]])

# Adicionar padrÃµes de frases (PHRASEMATCHER)
positivas_doc = list(nlp.pipe(palavras_positivas))  # Transforma lista de strings em Docs
negativas_doc = list(nlp.pipe(palavras_negativas))
phrase_matcher.add("POSITIVO", None, *positivas_doc)  # None = usar ORTH como atributo
phrase_matcher.add("NEGATIVO", None, *negativas_doc)

# 4. Criar extensÃ£o personalizada no objeto Doc
def detectar_sentimento(doc):
    matches = matcher(doc) + phrase_matcher(doc)
    positivos = sum(1 for match_id, _, _ in matches if nlp.vocab.strings[match_id] == "POSITIVO")
    negativos = sum(1 for match_id, _, _ in matches if nlp.vocab.strings[match_id] == "NEGATIVO")
    
    if positivos > negativos:
        return "POSITIVO"
    elif negativos > positivos:
        return "NEGATIVO"
    elif positivos == negativos and positivos > 0:
        return "NEUTRO"
    else:
        return "NEUTRO"

# Adiciona o atributo personalizado ._.sentimento
Doc.set_extension("sentimento", getter=detectar_sentimento)

# 5. Frases de teste
frases = [
    "Esse filme foi incrÃ­vel! Amei cada parte.",
    "O filme foi pÃ©ssimo, perdi meu tempo.",
    "Achei o filme ok, nada demais.",
    "Muito divertido, ri bastante!",
    "Cansativo e sem graÃ§a."
]

# 6. Executar a anÃ¡lise
print("ğŸ” AnÃ¡lise baseada em regras:\n")
for frase in frases:
    doc = nlp(frase)
    print(f"{frase} â†’ {doc._.sentimento}")
```

---

## ğŸ“ˆ Resultado esperado

```
ğŸ” AnÃ¡lise baseada em regras:

Esse filme foi incrÃ­vel! Amei cada parte. â†’ POSITIVO  
O filme foi pÃ©ssimo, perdi meu tempo. â†’ NEGATIVO  
Achei o filme ok, nada demais. â†’ NEUTRO  
Muito divertido, ri bastante! â†’ POSITIVO  
Cansativo e sem graÃ§a. â†’ NEGATIVO  
```

---

## ğŸ§© Possibilidades de expansÃ£o

- Adicionar pesos para diferentes palavras (por exemplo, "obra-prima" pode ter peso maior).
- Combinar com um modelo `textcat` treinado para um sistema hÃ­brido.
- Aplicar prÃ©-processamento (remoÃ§Ã£o de stopwords, lematizaÃ§Ã£o).
- Transformar isso em uma API com Flask ou FastAPI.
